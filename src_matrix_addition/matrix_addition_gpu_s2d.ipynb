{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc6e94-c59b-47ce-bf9b-874164bef4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "\n",
    "#define NUM_COL 10\n",
    "#define NUM_ROW 17\n",
    "\n",
    "struct Dim2 {\n",
    "\tunsigned char nc;\n",
    "\tunsigned char nr;\n",
    "};\n",
    "\n",
    "// Each thread produces one output matrix element.\n",
    "__global__ void matAddKernel0(float* d_C, float* d_A, float* d_B, struct Dim2 dim)\n",
    "{\n",
    "\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\tint row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "\tif (col < dim.nc && row < dim.nr) {\n",
    "\t\tint offset = row * dim.nc + col;\n",
    "\t\td_C[offset] = d_A[offset] + d_B[offset];\n",
    "\t}\n",
    "}\n",
    "\n",
    "// Each thread produces one output matrix row.\n",
    "__global__ void matAddKernel1(float* d_C, float* d_A, float* d_B, struct Dim2 dim)\n",
    "{\n",
    "\tint row = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\tif (row < dim.nr) {\n",
    "\t\tint offset = row * dim.nc;\n",
    "\t\tfor(int col = 0; col < dim.nc; col++) {\n",
    "\t\t\td_C[offset] = d_A[offset] + d_B[offset];\n",
    "\t\t\toffset++;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "// Each thread produces one output matrix column.\n",
    "__global__ void matAddKernel2(float* d_C, float* d_A, float* d_B, struct Dim2 dim)\n",
    "{\n",
    "\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\tif (col < dim.nc) {\n",
    "\t\tfor (int row = 0; row < dim.nr; row++) {\n",
    "\t\t\tint offset = row * dim.nc + col;\n",
    "\t\t\td_C[offset] = d_A[offset] + d_B[offset];\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "/*\n",
    " * A host stub function:  \n",
    " * allocating memory for the input and output matrices, \n",
    " * transferring input data to device, \n",
    " * launch the kernel, \n",
    " * transferring the output data to host, \n",
    " * and freeing the device memory for the input and output data.\n",
    " */\n",
    "void matAdd(float* h_C, float* h_A, float* h_B, struct Dim2 dim, char map)\n",
    "{\n",
    "\tfloat *d_A, *d_B, *d_C;    // pointers to device copies of A, B, C\n",
    "\tint size = dim.nr * dim.nc * sizeof(float);\n",
    "\n",
    "\t// Allocate device memory space for device copies of A, B, C\n",
    "\tcudaMalloc((void **) &d_A, size);\n",
    "\tcudaMalloc((void **) &d_B, size);\n",
    "\tcudaMalloc((void **) &d_C, size);\n",
    "\n",
    "\t// Copy matrices A and B from host memory to device memory\n",
    "\tcudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
    "\tcudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "\t// Launch the kernel function to have the device to perform the actual matrix addition\n",
    "\tint threads_per_block, no_of_blocks;\n",
    "\tswitch(map) {\n",
    "\t\tcase 'C':\n",
    "\t\t\tprintf(\"Exercise 1.C.\\n\");\n",
    "\t\t\tthreads_per_block = 32;\n",
    "\t\t\tno_of_blocks = ceil(dim.nr / (float) threads_per_block);\t\n",
    "\t\t\tmatAddKernel1<<<no_of_blocks, threads_per_block>>>(d_C, d_A, d_B, dim);\n",
    "\t\t\tbreak;\n",
    "\t\tcase 'D':\n",
    "\t\t\tprintf(\"Exercise 1.D.\\n\");\n",
    "\t\t\tthreads_per_block = 16;\n",
    "\t\t\tno_of_blocks = ceil(dim.nc / (float) threads_per_block);\t\n",
    "\t\t\tmatAddKernel2<<<no_of_blocks, threads_per_block>>>(d_C, d_A, d_B, dim);\n",
    "\t\t\tbreak;\n",
    "\t\tcase 'B':\n",
    "\t\tdefault:\n",
    "\t\t\tprintf(\"Exercise 1.A-B by default.\\n\");\n",
    "\t\t\tdim3 dimGrid(ceil(dim.nc / (float) 8), ceil(dim.nr / (float) 8), 1);\n",
    "\t\t\tdim3 dimBlock(8, 8, 1);\n",
    "\t\t\tmatAddKernel0<<<dimGrid,dimBlock>>>(d_C, d_A, d_B, dim);\n",
    "\t}\n",
    "\n",
    "\t// Copy result matrix C from the device memory to host memory\n",
    "\tcudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "\t// Free device memory for A, B, C\n",
    "\tcudaFree(d_A);\n",
    "\tcudaFree(d_B);\n",
    "\tcudaFree(d_C);\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[])\n",
    "{\n",
    "\tprintf(\"Enter a character to specify the element-to-thread mapping policy (B, C, or D): \");\n",
    "\tchar map;\n",
    "\tscanf(\"%c\", &map);\n",
    "\n",
    "\tint size = NUM_ROW * NUM_COL * sizeof(float);\n",
    "\n",
    "\t// Memory allocation for h_A, h_B, and h_C\n",
    "\tfloat *h_A = (float *) malloc(size);\n",
    "\tfloat *h_B = (float *) malloc(size);\n",
    "\tfloat *h_C = (float *) malloc(size);\n",
    "\n",
    "\t// Setup input values into each of n elements of h_A and h_B\n",
    "\tfor(int row = 0; row < NUM_ROW; row++) {\n",
    "\t\tfor(int col = 0; col < NUM_COL; col++) {\n",
    "\t\t\tint offset = row * NUM_COL + col;\n",
    "\t\t\th_A[offset] = (float) offset;\n",
    "\t\t\th_B[offset] = (float) offset;\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\t// Call the host function for matrix addition\n",
    "\tstruct Dim2 dim;\n",
    "\tdim.nc = NUM_COL;\n",
    "\tdim.nr = NUM_ROW;\n",
    "\tmatAdd(h_C, h_A, h_B, dim, map);\n",
    "\n",
    "\t// Output the results\n",
    "\tfor(int row = 0; row < NUM_ROW; row++) {\n",
    "\t\tfor(int col = 0; col < NUM_COL; col++) {\n",
    "\t\t\tint offset = row * NUM_COL + col;\n",
    "\t\t\tprintf(\"%.1f + %.1f = %.1f\\n\", h_A[offset] , h_B[offset], h_C[offset]);\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\t// Free host memory for A, B, C\n",
    "\tfree(h_A);\n",
    "\tfree(h_B);\n",
    "\tfree(h_C);\n",
    "\treturn 0;\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cuda-C",
   "language": "Cuda-C",
   "name": "cuda-c"
  },
  "language_info": {
   "file_extension": ".cu",
   "mimetype": "text/plain",
   "name": "cuda"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
